# LinkedIn Profile Validator Service

## Запуск сервиса с использованием Docker

### Сборка Docker-образа

```bash
# Из корня проекта
docker build -t linkedin-verifier:latest -f apps/linkedin_verifier/Dockerfile .
```

### Запуск контейнера

```bash
# Запуск с переменными окружения из .env файла
docker run -p 8000:8000 --env-file apps/linkedin_verifier/.env linkedin-verifier:latest

# Или с явным указанием переменных окружения
docker run -p 8000:8000 \
  -e DB_HOST=your-db-host \
  -e DB_PORT=5432 \
  -e DB_NAME=linkedin \
  -e DB_USER=user \
  -e DB_PASS=password \
  -e SCRAPIN_API_KEY=your-key-here \
  linkedin-verifier:latest
```

### Запуск с видимыми логами

```bash
# Запуск в интерактивном режиме (логи видны в консоли)
docker run -it -p 8000:8000 --env-file apps/linkedin_verifier/.env linkedin-verifier:latest

# Запуск в фоновом режиме с именем контейнера
docker run -d --name linkedin-verifier-container -p 8000:8000 --env-file apps/linkedin_verifier/.env linkedin-verifier:latest

# Просмотр логов запущенного контейнера
docker logs -f linkedin-verifier-container

# Просмотр логов с временными метками
docker logs -f --timestamps linkedin-verifier-container
```

### Остановка контейнера

```bash
# Если контейнер запущен с именем
docker stop linkedin-verifier-container

# Если контейнер запущен без имени, сначала узнайте его ID
docker ps
docker stop <container_id>

# Принудительная остановка (если обычная не срабатывает)
docker kill linkedin-verifier-container
```

### Проверка работоспособности

```bash
# Проверка статуса сервиса
curl http://localhost:8000/api/v1/linkedin/health
```

## Описание сервиса

Микросервис для валидации профилей LinkedIn. Проверяет опыт работы в целевых компаниях и сохраняет данные профилей.
Пока версия для ручной заливки профилей членов сообщества. Для pubsub готова на ~95%, еще нужно uv toml настроить, 
пока не успел,
для своего окружения я хардкорно ебашу ~uv pip install --force-reinstall  .\packages\common_db\ ))

Миграция на новые связные сущности добавлена как вторая миграция по счету после Initial 
(Сергей сделал с акутальным downgrade).
Для packages.common_db: __init__ модифицирован, добавлены нужные orm-модели.
Для демонстрационного запуска, отладки добавлены mock-данные (и соответсвующий флаг).

## Основные функции

1. **Асинхронная валидация через PubSub** (`main.py`)
   - Подписка на очередь профилей для валидации
   - Обработка входящих задач
   - Сохранение результатов в БД
   - Обновление лимитов API

2. **Ручной парсинг профилей** (`parse_profiles.py`)
   - Для обработки списков профилей от комьюнити-менеджеров
   - Пакетная валидация профилей
   - Сохранение результатов в БД (без user_id_fk)

3. **Миграция исторических данных** (`migrate_profiles.py`)
   - Выгрузка данных из БД в JSON файлы
   - Импорт данных из JSON в новую БД
   - Поддержка разных схем БД
   - Bulk insert с обработкой конфликтов
   - Приведение skills и languages к нижнему регистру

> **Важно**: Перед импортом данных необходимо очистить целевые таблицы через `TRUNCATE TABLE` с опцией `RESTART IDENTITY`, чтобы избежать конфликтов с sequence для id. Например:
> ```sql
> TRUNCATE TABLE linkedin_profiles, linkedin_education, linkedin_experience RESTART IDENTITY CASCADE;
> ```

## Структура базы данных

### linkedin_profiles
Основная таблица с данными профилей LinkedIn
- Базовая информация (имя, фамилия, URL и т.д.)
- is_open_to_work
- Денормализованные поля текущей работы:
  - `is_currently_employed` - работает ли сейчас
  - `current_jobs_count` - количество текущих мест работы
  - `current_company_label` - название текущей компании
  - `current_position_title` - текущая должность
  - и др.
- Денормализованные поля целевой компании:
  - `is_target_company_found` - найдена ли целевая компания
  - `target_company_positions_count` - количество позиций
  - `target_company_label` - название компании
  - `target_position_title` - последняя должность
  - и др.

### linkedin_experience
История работы
- Связь с профилем (FK)
- Информация о каждой позиции
- Накопительное хранение (новые записи добавляются, старые сохраняются)

### linkedin_education
История образования
- Связь с профилем (FK)
- Информация о каждом месте учебы
- Накопительное хранение

### linkedin_raw_data
Сырые данные от API - чтобы хранить ответы платных сервисов
- `target_linkedin_url` - URL профиля
- `raw_data` - полный ответ API (JSONB)
- `parsed_date` - дата парсинга

### linkedin_api_limits
Лимиты API провайдеров
- Тип провайдера (SCRAPIN/TOMQUIRK)
- Идентификатор провайдера
- Оставшиеся кредиты/запросы
- Время обновления

## Логика работы

1. **Получение задачи**
   - Из PubSub очереди (асинхронно)
   - Из файла с профилями (ручной запуск)

2. **Получение данных**
   - Запрос к API LinkedIn через провайдера
   - Сохранение сырых данных
   - Валидация и преобразование данных

3. **Обработка опыта работы**
   
   a. **Определение текущей работы**
   - Поиск всех позиций без даты окончания
   - Сортировка по дате начала (новые сверху)
   - Выбор самой новой позиции как текущей
   - Сохранение денормализованных полей в профиле
   
   b. **Поиск работы в целевой компании**
   - Case-insensitive поиск по названию компании
   - Сортировка всех найденных позиций по дате
   - Определение последней позиции в компании
   - Проверка, является ли текущей работой
   
   c. **Особенности**
   - Даты хранятся с первым днем месяца (API дает только месяц/год)
   - Для отсутствующих дат используется 1900-01-01
   - Проверяется корректность периодов работы
   - Учитывается возможность нескольких текущих позиций

4. **Сохранение данных**
   - Сохранение/обновление основного профиля
   - Добавление новых записей работы/образования
   - Обновление лимитов API

## Особенности реализации

1. **Денормализация данных**
   - Часто используемые поля вынесены в основную таблицу
   - Упрощает запросы и улучшает производительность
   - Требует поддержания актуальности при обновлениях

2. **Накопительное хранение**
   - Новые записи работы/образования добавляются
   - Старые записи сохраняются для истории
   - Позволяет отслеживать изменения в карьере

3. **Отказоустойчивость**
   - Сохранение сырых данных в отдельной транзакции
   - Логирование всех этапов обработки
   - Обработка ошибок API и сети

## TODO:

### 1. Валидация опыта работы

**Валидация верификации - валидация опыта работы в легетимных компаниях**
- Продуктовая логика - изучить, реализовать

### 2. Интеграция

**Связь с профилями пользователей**
- Интеграция с основной базой пользователей

**Уведомления для кураторов**
- Система оповещений об изменениях
- Настройка правил уведомлений
- Различные каналы доставки - настройка гугл клауд pubsub

**API**
- Добавить в гейтвей http sub-ручку постановки заданий (от комьюнити-менеджеров)

### 3. Провайдеры API

**Поддержка TomQuirk API**
- Реализация нового провайдера - для управления аккаунтом

**Мониторинг лимитов**
- Предупреждения о лимитах

### 4. Прочее
- LLM генерить описание профиля для дальнейшего использования в мэтчинге
- Где хранить полe is_verified - нужно потом скорее всего для реализации безопасности эндпоинтов гейтвея
- Уточнить, какой логгер юзаем
- тест pubsub
- Docker + test in minicube + google secrets, конфигурация для облака
- Допроверить различные raise
- UV: toml, lock
- Тесты
- Вырезать fastapi

## Архитектура сервиса

### 1. Провайдеры данных LinkedIn

**Фабрика парсеров**
- Абстрактный класс `LinkedInParser` с общим интерфейсом
- Реализации для разных провайдеров:
  - `ScrapinParser` - основной парсер через Scrapin API
  - `TomQuirkParser` - для управления аккаунтом (в разработке)
- Фабричный метод создает нужный парсер на основе конфигурации

**Управление провайдерами**
- Автоматический выбор доступного провайдера
- Проверка лимитов перед использованием
- Переключение при исчерпании лимитов
- Обработка специфичных ошибок каждого провайдера

### 2. Слои сервиса

**Repository Layer**
- Абстракция для работы с API LinkedIn
- Обработка ошибок сети
- Управление лимитами запросов

**Service Layer**
- Бизнес-логика обработки профилей
- Валидация данных
- Преобразование форматов
- Подготовка данных для сохранения

**Database Layer**
- ORM модели для работы с БД
- Транзакционное сохранение
- Накопительное хранение истории
- Денормализация данных

### 3. Обработка сообщений

**PubSub Consumer**
- Асинхронная обработка задач
- Управление подпиской
- Обработка ошибок
- Подтверждение выполнения

**Message Handler**
- Валидация входящих сообщений
- Маршрутизация задач
- Формирование ответов
- Отправка уведомлений

### 4. Конфигурация

**Провайдеры**
```python
class LinkedInParserType(str, Enum):
    SCRAPIN = "scrapin"
    TOMQUIRK = "tomquirk"


TODO: при миграции данных последовательности перв. ключей обновить - иначе конфликты при записи новых данных