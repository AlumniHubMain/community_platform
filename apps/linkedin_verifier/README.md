# LinkedIn Profile Verifier Service

Асинхронный микросервис для парсинга профилей LinkedIn через Scrapin.io API с отслеживанием лимитов и асинхронной обработкой через Google Cloud Pub/Sub.

## Архитектура

### Основные компоненты

1. **База данных** (`app/db/`)
   - Асинхронное подключение к PostgreSQL через SQLAlchemy
   - Модели данных в `models/`
   - Единая точка подключения в `base.py`

2. **API Layer** (`app/api/`)
   - FastAPI endpoints
   - Асинхронные обработчики
   - Валидация входных данных

3. **Pub/Sub** (`app/pubsub/`)
   - Google Cloud Pub/Sub интеграция
   - Асинхронные обработчики сообщений
   - Система оповещений о лимитах

4. **Внешние API** (`app/repositories/`)
   - Scrapin.io API клиент
   - Абстракция через репозитории
   - Фабрика для создания клиентов

5. **Бизнес-логика** (`app/services/`)
   - Обработка профилей
   - Управление лимитами
   - Координация компонентов

## Потоки данных

1. **Pub/Sub Flow**   ```
   Message -> Subscriber -> Handler -> Service -> Repository -> API
                                             -> Database   ```

2. **REST API Flow**   ```
   Request -> Endpoint -> Service -> Repository -> API
                                -> Database   ```

## Конфигурация

Настройки в `.env`:



## API Reference

- `GET /api/v1/linkedin/limits` - Лимиты API
- `POST /api/v1/linkedin/profile/{username}` - Парсинг профиля
- `GET /api/v1/linkedin/health` - Проверка сервиса



## Структура проекта






linkedin_verifier/
├── app/
│   ├── api/
│   │   └── v1/
│   │       ├── endpoints/
│   │       │   └── linkedin.py
│   │       └── api.py
│   ├── core/
│   │   └── config.py
│   ├── db/
│   │   ├── models/
│   │   │   ├── __init__.py
│   │   │   ├── limits.py
│   │   │   └── profile.py
│   │   ├── base.py
│   │   ├── base_class.py
│   │   └── session.py
│   ├── pubsub/
│   │   ├── base.py
│   │   ├── google.py
│   │   ├── handlers.py
│   │   ├── publisher.py
│   │   └── subscriber.py
│   ├── repositories/
│   │   ├── factory.py
│   │   └── linkedin.py
│   ├── schemas/
│   │   ├── linkedin.py
│   │   └── pubsub.py
│   └── services/
│       └── linkedin.py
└── main.py




что за папка db и нахуя она нужна?

Папка db содержит бзовые классы и утилиты для работы с базой данных. В ней обычно находятся:
base_class.py - базовый класс для всех моделей SQLAlchemy
session.py - функции для создания и управления сессиями БД
base.py - импорты всех моделей для Alembic миграций
Давайте посмотрим на необходимые файлы:
Эта папка нужна для:
Централизованного управления подключением к БД
Предоставления базового класса для всех моделей
Управления сессиями БД
Поддержки миграций через Alembic
Все модели наследуются от Base из base_class.py, а сессии БД создаются через get_db() из session.py.
сделай создание экземпляра базы как в папке notifications

Да, давайте сделаем создание базы данных как в notifications. Обновим файл session.py:
Основные изменения:
Используем asyncpg вместо синхронного дра��вера
Используем асинхронный движок и сессии
Используем асинхронный контекстный менеджер для сессий
Добавили типизацию для асинхронного генератора
Теперь все операции с БД будут асинхронными, что соответствует стилю из notifications.
а для чего папка models тогда? 
посмотри внимательно, где у нас противоречия в миктросервисе нашем
и сделай подробный readme как что у нас устроено, работает, вызывается, для чего, структуру проекта там опииши

Да, у нас есть несколько противоречий:
Асинхронность/синхронность:
БД работает асинхронно (AsyncSession)
Но репозиторий LinkedInScrapinRepository использует синхронные методы
API endpoints тоже синхронные
PubSub handlers асинхронные
Структура:
У нас есть папка models для SQLAlchemy моделей
И папка db тоже для работы с БД
Это может запутать, обычно всё связанное с БД держат в одном месте
Давайте я создам подро��ный README:
linkedin_verifier/
├── app/
│ ├── api/ # API endpoints
│ │ └── v1/
│ │ └── endpoints/
│ │ └── linkedin.py # Ручные операции с профилями
│ ├── core/ # Ядро приложения
│ │ └── config.py # Конфигурация и настройки
│ ├── db/ # Работа с базой данных
│ │ ├── base.py # Импорты моделей для Alembic
│ │ ├── base_class.py # Базовый класс SQLAlchemy
│ │ └── session.py # Управление сессиями БД
│ ├── models/ # SQLAlchemy модели
│ │ ├── limits.py # Модель лимитов API
│ │ └── profile.py # Модели профиля и связанных данных
│ ├── pubsub/ # Работа с Google Cloud Pub/Sub
│ │ ├── base.py # Базовый класс для pub/sub
│ │ ├── google.py # Реализация для Google Cloud
│ │ ├── handlers.py # Обработчики сообщений
│ │ ├── publisher.py # Публикация сообщений
│ │ └── subscriber.py # Подписка на сообщения
│ ├── repositories/ # Работа с внешними API
│ │ ├── factory.py # Фабрика репозиториев
│ │ └── linkedin.py # Реализации API клиентов
│ ├── schemas/ # Pydantic модели
│ │ ├── linkedin.py # Схемы данных LinkedIn
│ │ └── pubsub.py # Схемы для pub/sub сообщений
│ └── services/ # Бизнес-логика
│ └── linkedin.py # Сервис обработки профилей
└── main.py # Точка входа приложения






linkedin_verifier/
├── app/
│ ├── api/ # REST API endpoints
│ │ └── v1/
│ │ ├── endpoints/
│ │ │ └── linkedin.py # Обработчики запросов
│ │ └── api.py # Роутер API
│ ├── core/ # Конфигурация
│ │ └── config.py # Настройки приложения
│ ├── db/ # База данных
│ │ ├── models/ # SQLAlchemy модели
│ │ │ ├── limits.py # Лимиты API
│ │ │ └── profile.py # Профили LinkedIn
│ │ ├── base.py # Импорты для Alembic
│ │ ├── base_class.py # Базовый класс моделей
│ │ └── session.py # Управление сессиями
│ ├── pubsub/ # Pub/Sub функционал
│ │ ├── base.py # Базовый интерфейс
│ │ ├── google.py # Google Cloud реализация
│ │ ├── handlers.py # Обработчики сообщений
│ │ ├── publisher.py # Отправка сообщений
│ │ └── subscriber.py # Получение сообщений
│ ├── repositories/ # Внешние API
│ │ ├── factory.py # Фабрика репозиториев
│ │ └── linkedin.py # Scrapin.io клиент
│ ├── schemas/ # Pydantic модели
│ │ ├── linkedin.py # Схемы данных
│ │ └── pubsub.py # Схемы сообщений
│ └── services/ # Бизнес-логика
│ └── linkedin.py # Сервис профилей
└── main.py # Точка входа



## Основной функционал

1. **Парсинг профилей**
   - Асинхронные запросы к Scrapin.io API
   - Валидация через Pydantic
   - Сохранение в PostgreSQL

2. **Мониторинг лимитов**
   - Отслеживание при каждом запросе
   - Алерты через Pub/Sub
   - История в БД

3. **Асинхронная обработка**
   - Pub/Sub для заданий
   - Очереди сообщений
   - Обработка ошибок

## Запуск

1. Переменные окружения:

linkedin_verifier/app/pubsub/
├── __init__.py
├── base.py          # Абстрактный базовый класс
├── factory.py       # Фабрика для создания клиентов
├── google.py        # Google реализация
├── handlers.py      # Обработчики сообщений
├── nats.py          # NATS реализация



base.py - интерфейс
factory.py - создание клиентов
google.py, nats.py - реализации
handlers.py - обработчики


handlers.py - это обработчики сообщений, которые приходят через pub/sub. Их основная задача - получить сообщение и выполнить нужное действие.
Текущая реализация:
Что делает:
Получает сырые данные из сообщения
Валидирует их через Pydantic модель
Вызывает соответствующий метод сервиса
Логирует результат
Они вынесены отдельно потому что:
Разделение ответственности - обработчики только принимают сообщения и вызывают нужные сервисы
2. Переиспользуемость - один обработчик может использоваться разными pub/sub клиентами
3. Тестируемость - легко мокать и тестировать отдельно от pub/sub инфраструктуры










Теперь:
Хендлер возвращает статус обработки
При неудаче сообщение вернется в очередь
Настроены повторные попытки с ограничением
Явное подтверждение успешной обработки
Логирование всех этапов
Хотите, чтобы я показал аналогичные изменения для Google PubSub клиента?




Основные изменения:
Добавлен механизм подтверждения (ack/nack)
Настроен контроль потока сообщений
Обработка по одному сообщению
Возможность повторной обработки при неудаче
Правильное закрытие подписки
В Google PubSub повторы настраиваются на уровне подписки в Google Cloud Console или через API при создании подписки:
message_retention_duration
ack_deadline_seconds
retry_policy
Хотите, чтобы я показал, как настроить эти параметры через API?











linkedin_verifier/app/pubsub/
├── __init__.py
├── base.py          # Абстрактный интерфейс для всех клиентов
├── factory.py       # Фабрика для создания нужного клиента
├── google.py        # Google PubSub реализация
├── handlers.py      # Обработчики сообщений
└── nats.py          # NATS реализация

Конфликтов больше нет:
✅ Единый интерфейс через PubSubClient
✅ Фабрика для создания клиентов
✅ Каждый клиент реализует и публикацию, и подписку
✅ Обработчики возвращают статус для повторов
✅ Механизм подтверждений (ack/nack) в обоих клиентах
Поток данных теперь такой:

Публикация:
Service -> PubSubClient (Google/NATS) -> Message Broker

Подписка:
Message Broker -> PubSubClient -> Handler -> Service
                              <- Status    <- Result






